{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../../../')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from src.difsched.config import getExpConfig, visualizeExpConfig\n",
    "from src.difsched.config import getEnvConfig, visualizeEnvConfig\n",
    "from src.difsched.config import getDatasetConfig, visualizeDatasetConfig\n",
    "from src.difsched.env.EnvironmentSim import createEnv\n",
    "from src.difsched.utils.EnvInterface import EnvInterface\n",
    "from src.difsched.training import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'N_diffusion_steps':30,\n",
    "    'schedule_type': \"vp\",\n",
    "    'abs_action_max': 1.0,\n",
    "    'gamma': 0.99,\n",
    "    'lr': 5e-4,\n",
    "    'decay_lr': True,\n",
    "    'weight_decay': 0.0,\n",
    "    'num_critics': 8,\n",
    "    'lcb_coef': 0.15,\n",
    "    'q_sample_eta': 1.0,\n",
    "    'weight_entropy_loss': 0.01,\n",
    "    'weight_q_loss': 1.0,\n",
    "    'approximate_action': True,\n",
    "    'ema_tau': 0.001,\n",
    "    'ema_period': 20,\n",
    "    'ema_begin_update': 1000,\n",
    "    'layer_norm': True,\n",
    "    'grad_clip': 3.0,\n",
    "    'device': 'cuda',\n",
    "}\n",
    "\n",
    "\n",
    "trainingConfig = {\n",
    "    'BC_loss': True,\n",
    "    'iterations': 100,\n",
    "    'batch_size': 100,\n",
    "    'LEN_eval': 50,\n",
    "    'report_period': 10,\n",
    "    'len_period': 500,\n",
    "    'warm_up_period': 50,\n",
    "    'max_sp_ratio': 1.0,\n",
    "    'min_sp_ratio': 0.5,\n",
    "    'max_weight_bc_loss': 1.0,\n",
    "    'min_weight_bc_loss': 0.2,\n",
    "    'rb_capacity': 30000\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_train_config_idx: 0\n",
      "dataset_test_config_idx: 2\n",
      "env_config_idx: 0\n",
      "==================================================\n",
      "Environment Configuration\n",
      "==================================================\n",
      "Number of Users:        8\n",
      "Window Length:          200\n",
      "Dataflow:               thumb_fr\n",
      "Sigmoid K List:         [0.1, 0.2, 0.3, 0.4, 0.5]\n",
      "Sigmoid S List:         [10.0, 10.0, 10.0, 10.0, 10.0]\n",
      "Resource Bar:           5\n",
      "Bandwidth:              100\n",
      "Sub Agents:             [[0, 0]]\n",
      "User Map:               [[0, 1, 2, 3], [4, 5, 6, 7]]\n",
      "==================================================\n",
      "==================================================\n",
      "Dataset Configuration\n",
      "==================================================\n",
      "Number of Users:        8\n",
      "Window Length:          200\n",
      "N_aggregation:          4\n",
      "Dataflow:               thumb_fr\n",
      "Random Seed:            999\n",
      "Resource Bar:           5\n",
      "Bandwidth:              100\n",
      "Sigmoid K List:         [0.3]\n",
      "Sigmoid S List:         [10.0]\n",
      "Sub Agents:             [[0, 0]]\n",
      "User Map:               [[0, 1, 2, 3], [4, 5, 6, 7]]\n",
      "==================================================\n",
      "Avg. packet loss rate: 0.32451573558442404\n",
      "length of dataset: 10000\n",
      "1.0 0.2\n",
      "Expert's Reward: 0.6743894815444946\n",
      "state_dim: 8, action_dim: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Iteration 10====================\n",
      "Ld: 0.14892275653779508, Lq: 0.6739043366909027, Le: -1.5640923225879668, loss_Q: 0.008429121258668602\n",
      "Avg. Reward: 0.4452561476330543, sample_ratio: 0.9, weight_bc_loss: 0.84\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.40540113605709005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.40055308935597456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.3985655590823134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.3970601090756587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.3917101344244475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.3901908546721513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.383229072626394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.3756676720242898\n",
      "====================Iteration 20====================\n",
      "Ld: 0.15229831464588642, Lq: 0.6861505633592606, Le: -1.544719054698944, loss_Q: 0.008954102974385023\n",
      "Avg. Reward: 0.38822665955821173, sample_ratio: 0.8, weight_bc_loss: 0.6799999999999999\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.37108781998370655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.37100166921270017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.368463042506357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.362407185560114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.36123955611502157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.3549494447384173\n",
      "====================Iteration 30====================\n",
      "Ld: 0.12953221619129182, Lq: 0.6968738669157029, Le: -1.5274147033691405, loss_Q: 0.009417618233710527\n",
      "Avg. Reward: 0.36355914852817806, sample_ratio: 0.7, weight_bc_loss: 0.52\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.35368246658335406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.3508758782127498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.3483261992635627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.34327250553203353\n",
      "====================Iteration 40====================\n",
      "Ld: 0.1472952302545309, Lq: 0.7137804299592971, Le: -1.4640526390075683, loss_Q: 0.009803332891315221\n",
      "Avg. Reward: 0.34888456093289866, sample_ratio: 0.6, weight_bc_loss: 0.36\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.34279333260895384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.33940872626620894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Iteration 50====================\n",
      "Ld: 0.14126367874443532, Lq: 0.7351236653327942, Le: -1.4140260767936708, loss_Q: 0.009907772224396467\n",
      "Avg. Reward: 0.34629783942548775, sample_ratio: 0.5, weight_bc_loss: 0.2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Iteration 60====================\n",
      "Ld: 0.1622897854447365, Lq: 0.7436058729887008, Le: -1.4541399586200714, loss_Q: 0.010037265047430992\n",
      "Avg. Reward: 0.34929507592221043, sample_ratio: 0.5, weight_bc_loss: 0.2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Iteration 70====================\n",
      "Ld: 0.1381592170894146, Lq: 0.7392136859893799, Le: -1.5042879056930543, loss_Q: 0.00994401636067778\n",
      "Avg. Reward: 0.34927539555431786, sample_ratio: 0.5, weight_bc_loss: 0.2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.336385300626665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.3325917621811684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Iteration 80====================\n",
      "Ld: 0.14725202798843384, Lq: 0.7452993202209472, Le: -1.517020364999771, loss_Q: 0.010411682315170765\n",
      "Avg. Reward: 0.3409068616423959, sample_ratio: 0.5, weight_bc_loss: 0.2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Iteration 90====================\n",
      "Ld: 0.12379820868372918, Lq: 0.7490597504377365, Le: -1.5481984901428223, loss_Q: 0.009829280893318354\n",
      "Avg. Reward: 0.338600877931043, sample_ratio: 0.5, weight_bc_loss: 0.2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Iteration 100====================\n",
      "Ld: 0.13573652379214762, Lq: 0.7612938672304154, Le: -1.5370420050621032, loss_Q: 0.010318070915527642\n",
      "Avg. Reward: 0.3464769192801323, sample_ratio: 0.5, weight_bc_loss: 0.2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Iteration 110====================\n",
      "Ld: 0.11611989922821522, Lq: 0.7707113760709763, Le: -1.5661921250820159, loss_Q: 0.009696564665064215\n",
      "Avg. Reward: 0.34708288854869995, sample_ratio: 0.5, weight_bc_loss: 0.2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Iteration 120====================\n",
      "Ld: 0.12385011650621891, Lq: 0.7846882021427155, Le: -1.5604680120944976, loss_Q: 0.01002985866740346\n",
      "Avg. Reward: 0.34594034811381, sample_ratio: 0.5, weight_bc_loss: 0.2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 1_best, smoothed reward: 0.3324044683834506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Iteration 130====================\n",
      "Ld: 0.11206394128501415, Lq: 0.802804805636406, Le: -1.5919020569324493, loss_Q: 0.009520480539649726\n",
      "Avg. Reward: 0.3394311279121512, sample_ratio: 0.5, weight_bc_loss: 0.2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Iteration 140====================\n",
      "Ld: 0.1185513886809349, Lq: 0.8202411150932312, Le: -1.5872066390514374, loss_Q: 0.009718218077905476\n",
      "Avg. Reward: 0.33586743871216174, sample_ratio: 0.5, weight_bc_loss: 0.2\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expert's Reward: 0.6759028434753418\n",
      "state_dim: 8, action_dim: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(save_folder):\n\u001b[0;32m     34\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(save_folder)\n\u001b[1;32m---> 36\u001b[0m \u001b[43mtraining\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainingConfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_off\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhyperparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvInterface\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_exp_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\Diffusion-offRL\\diffusion_resource_schduling_intra_slice\\src\\notebooks\\02_training\\dql_training\\../../../..\\src\\difsched\\training\\training.py:65\u001b[0m, in \u001b[0;36mtraining\u001b[1;34m(trainingConfig, dataset_off, hyperparams, env, envInterface, save_folder, N_exp_list)\u001b[0m\n\u001b[0;32m     61\u001b[0m _, explore_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(agent, env, envInterface, LEN_eval\u001b[38;5;241m=\u001b[39mLEN_eval, obvMode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredicted\u001b[39m\u001b[38;5;124m\"\u001b[39m, \n\u001b[0;32m     62\u001b[0m                     sample_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexploration\u001b[39m\u001b[38;5;124m\"\u001b[39m, N_action_candidates\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, \n\u001b[0;32m     63\u001b[0m                     eta\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m3.0\u001b[39m), verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     64\u001b[0m dataSamplerOn\u001b[38;5;241m.\u001b[39maddOnline(explore_data)\n\u001b[1;32m---> 65\u001b[0m reward, offpolicy_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43meval\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvInterface\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLEN_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mLEN_eval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobvMode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpredicted\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m                            \u001b[49m\u001b[43msample_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgreedy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_action_candidates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     67\u001b[0m dataSamplerOn\u001b[38;5;241m.\u001b[39maddOnline(offpolicy_data)\n\u001b[0;32m     68\u001b[0m sample_ratio \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmax([min_sp_ratio, max_sp_ratio \u001b[38;5;241m-\u001b[39m ((max_sp_ratio\u001b[38;5;241m-\u001b[39mmin_sp_ratio)\u001b[38;5;241m/\u001b[39mwarm_up_period) \u001b[38;5;241m*\u001b[39m idx_episode])\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\Diffusion-offRL\\diffusion_resource_schduling_intra_slice\\src\\notebooks\\02_training\\dql_training\\../../../..\\src\\difsched\\evaluation\\evaluation.py:67\u001b[0m, in \u001b[0;36meval\u001b[1;34m(agent, env, envInterface, LEN_eval, obvMode, mode, type, sample_method, N_action_candidates, eta, verbose)\u001b[0m\n\u001b[0;32m     65\u001b[0m info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservations\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactions\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrewards\u001b[39m\u001b[38;5;124m'\u001b[39m: [], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnext_observations\u001b[39m\u001b[38;5;124m'\u001b[39m: []}\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m window \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(LEN_eval), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation windows\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m verbose):\n\u001b[1;32m---> 67\u001b[0m     u, action, reward, u_next \u001b[38;5;241m=\u001b[39m \u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m        \u001b[49m\u001b[43magent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menvInterface\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobvMode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_method\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_action_candidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m#============ Record Results ============\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobservations\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(u)\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\Diffusion-offRL\\diffusion_resource_schduling_intra_slice\\src\\notebooks\\02_training\\dql_training\\../../../..\\src\\difsched\\evaluation\\evaluation.py:38\u001b[0m, in \u001b[0;36m_step\u001b[1;34m(agent, env, envInterface, obvMode, sample_method, N_action_candidates, eta)\u001b[0m\n\u001b[0;32m     31\u001b[0m     a \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39msample(\n\u001b[0;32m     32\u001b[0m         s, \n\u001b[0;32m     33\u001b[0m         sample_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEAS\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     34\u001b[0m         N\u001b[38;5;241m=\u001b[39mN_action_candidates, \n\u001b[0;32m     35\u001b[0m         eta \u001b[38;5;241m=\u001b[39m eta\n\u001b[0;32m     36\u001b[0m     )\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 38\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     39\u001b[0m \u001b[43m        \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     40\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_method\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[43m        \u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_action_candidates\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     42\u001b[0m \u001b[43m        \u001b[49m\u001b[43meta\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     44\u001b[0m r \u001b[38;5;241m=\u001b[39m envInterface\u001b[38;5;241m.\u001b[39mpostprocess_action(a)\n\u001b[0;32m     45\u001b[0m reward \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mapplyActions(r)\n",
      "File \u001b[1;32mc:\\Users\\Ye\\miniconda3\\envs\\traffic_predictor_3_9\\lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[1;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\Diffusion-offRL\\diffusion_resource_schduling_intra_slice\\src\\notebooks\\02_training\\dql_training\\../../../..\\src\\difsched\\agents\\DiffusionQL\\DQL_Q_esmb.py:181\u001b[0m, in \u001b[0;36mDQL_Q_esmb.sample\u001b[1;34m(self, s, sample_method, N, eta)\u001b[0m\n\u001b[0;32m    179\u001b[0m B \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    180\u001b[0m s_rep \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mexpand(B, N, s\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, s\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 181\u001b[0m a_cand \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample_DDIM\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms_rep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m q_cand \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcritic_target\u001b[38;5;241m.\u001b[39mtarget\u001b[38;5;241m.\u001b[39mq_min(s_rep, a_cand)\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview(B, N)\n\u001b[0;32m    183\u001b[0m a_cand \u001b[38;5;241m=\u001b[39m a_cand\u001b[38;5;241m.\u001b[39mview(B, N, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\Diffusion-offRL\\diffusion_resource_schduling_intra_slice\\src\\notebooks\\02_training\\dql_training\\../../../..\\src\\difsched\\agents\\DiffusionQL\\Actors.py:103\u001b[0m, in \u001b[0;36mDiffusionPolicy.sample_DDIM\u001b[1;34m(self, s, eta)\u001b[0m\n\u001b[0;32m    101\u001b[0m sigma_t \u001b[38;5;241m=\u001b[39m eta \u001b[38;5;241m*\u001b[39m ((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha_prev) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha))\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha\u001b[38;5;241m/\u001b[39malpha_prev)\u001b[38;5;241m.\u001b[39msqrt()\n\u001b[0;32m    102\u001b[0m \u001b[38;5;66;03m#sigma_t = eta *(1 - alpha/alpha_prev).sqrt()\u001b[39;00m\n\u001b[1;32m--> 103\u001b[0m x0_pred \u001b[38;5;241m=\u001b[39m alpha_prev\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m*\u001b[39m (a \u001b[38;5;241m-\u001b[39m (\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43malpha\u001b[49m)\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m*\u001b[39m eps) \u001b[38;5;241m/\u001b[39m alpha\u001b[38;5;241m.\u001b[39msqrt()\n\u001b[0;32m    104\u001b[0m direct_point_x \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m alpha_prev \u001b[38;5;241m-\u001b[39m sigma_t\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m))\u001b[38;5;241m.\u001b[39mclamp(\u001b[38;5;241m0.0\u001b[39m)\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m*\u001b[39m eps\n\u001b[0;32m    105\u001b[0m noise_term \u001b[38;5;241m=\u001b[39m sigma_t \u001b[38;5;241m*\u001b[39m noises[step \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Ye\\miniconda3\\envs\\traffic_predictor_3_9\\lib\\site-packages\\torch\\_tensor.py:39\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function(args):\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Ye\\miniconda3\\envs\\traffic_predictor_3_9\\lib\\site-packages\\torch\\_tensor.py:1028\u001b[0m, in \u001b[0;36mTensor.__rsub__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m   1026\u001b[0m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[0;32m   1027\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rsub__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m-> 1028\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_VariableFunctions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsub\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for expConfigIdx in range(4):\n",
    "    expParams = getExpConfig(expConfigIdx)\n",
    "    visualizeExpConfig(expParams)\n",
    "\n",
    "    envConfigIdx = expParams['env_config_idx']\n",
    "    envParams = getEnvConfig(envConfigIdx)\n",
    "    visualizeEnvConfig(envParams)\n",
    "\n",
    "    datasetConfigIdx = expParams['dataset_train_config_idx']\n",
    "    datasetParams = getDatasetConfig(datasetConfigIdx)\n",
    "    visualizeDatasetConfig(datasetParams)\n",
    "\n",
    "    trafficDataParentPath = f'../../../../data/processed/traffic'\n",
    "    env = createEnv(envParams, trafficDataParentPath)\n",
    "    env.selectMode(mode=\"train\", type=\"data\")\n",
    "    envInterface = EnvInterface(envParams, discrete_state=False)\n",
    "\n",
    "    datasetFolder = f'../../../../data/processed/offline_dataset'\n",
    "    with open(f'{datasetFolder}/subOptimalAgent_encConfig{datasetConfigIdx}_{envParams[\"sub_agents_idx\"]}.pkl', 'rb') as f:\n",
    "        dataset_expert = pickle.load(f)\n",
    "    dataset_off = {\n",
    "        'observations': dataset_expert['uRecord'],     \n",
    "        'actions': dataset_expert['actionsRecord'], \n",
    "        'rewards': dataset_expert['rewardRecord'], \n",
    "        'next_observations': dataset_expert['uNextRecord']\n",
    "    }\n",
    "    print(f\"Avg. packet loss rate: {np.mean(dataset_expert['rewardRecord'])}\")\n",
    "    print(f\"length of dataset: {len(dataset_off['observations'])}\")\n",
    "\n",
    "    # With BC\n",
    "    \n",
    "    save_folder = f\"../../../../data/results/dql/config_{expConfigIdx}/long\"\n",
    "    if not os.path.exists(save_folder):\n",
    "        os.makedirs(save_folder)\n",
    "\n",
    "    training(\n",
    "        trainingConfig, dataset_off, hyperparams, env, envInterface, save_folder, N_exp_list=[1,2]\n",
    "    )\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic_predictor_3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
