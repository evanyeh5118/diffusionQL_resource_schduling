{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../../../')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from src.difsched.config import getExpConfig, visualizeExpConfig\n",
    "from src.difsched.config import getEnvConfig, visualizeEnvConfig\n",
    "from src.difsched.config import getDatasetConfig, visualizeDatasetConfig\n",
    "from src.difsched.env.EnvironmentSim import createEnv\n",
    "from src.difsched.utils.EnvInterface import EnvInterface\n",
    "from src.difsched.training import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    'N_diffusion_steps':30,\n",
    "    'schedule_type': \"vp\",\n",
    "    'abs_action_max': 1.0,\n",
    "    'gamma': 0.99,\n",
    "    'lr': 5e-4,\n",
    "    'decay_lr': True,\n",
    "    'weight_decay': 0.0,\n",
    "    'num_critics': 8,\n",
    "    'lcb_coef': 0.15,\n",
    "    'q_sample_eta': 1.0,\n",
    "    'weight_entropy_loss': 0.01,\n",
    "    'weight_q_loss': 1.0,\n",
    "    'approximate_action': True,\n",
    "    'ema_tau': 0.001,\n",
    "    'ema_period': 20,\n",
    "    'ema_begin_update': 1000,\n",
    "    'layer_norm': True,\n",
    "    'grad_clip': 3.0,\n",
    "    'device': 'cuda',\n",
    "}\n",
    "\n",
    "trainingConfig = {\n",
    "    'iterations': 100,\n",
    "    'batch_size': 100,\n",
    "    'LEN_eval': 50,\n",
    "    'report_period': 10,\n",
    "    'len_period': 50,\n",
    "    'warm_up_period': 50,\n",
    "    'max_sp_ratio': 1.0,\n",
    "    'min_sp_ratio': 0.5,\n",
    "    'max_weight_bc_loss': 1.0,\n",
    "    'min_weight_bc_loss': 1.0,\n",
    "    'rb_capacity': 30000\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_config_idx: 5\n",
      "env_config_idx: 3\n",
      "==================================================\n",
      "Environment Configuration\n",
      "==================================================\n",
      "Number of Users:        20\n",
      "Window Length:          200\n",
      "Dataflow:               thumb_bk\n",
      "Sigmoid K List:         [0.1, 0.2, 0.3, 0.4, 0.5]\n",
      "Sigmoid S List:         [10.0, 10.0, 10.0, 10.0, 10.0]\n",
      "Resource Bar:           5\n",
      "Bandwidth:              200\n",
      "Sub Agents:             [[1, 1, 1, 1, 1]]\n",
      "User Map:               [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19]]\n",
      "==================================================\n",
      "==================================================\n",
      "Dataset Configuration\n",
      "==================================================\n",
      "Number of Users:        20\n",
      "Window Length:          200\n",
      "N_aggregation:          4\n",
      "Dataflow:               thumb_bk\n",
      "Random Seed:            999\n",
      "Resource Bar:           5\n",
      "Bandwidth:              200\n",
      "Sigmoid K List:         [0.3]\n",
      "Sigmoid S List:         [10.0]\n",
      "Sub Agents:             [[1, 1, 1, 1, 1]]\n",
      "User Map:               [[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15], [16, 17, 18, 19]]\n",
      "==================================================\n",
      "Avg. packet loss rate: 0.47515393810082424\n",
      "length of dataset: 10000\n",
      "Expert's Reward: 0.5251383185386658\n",
      "state_dim: 20, action_dim: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================Iteration 10====================\n",
      "Ld: 0.1252062913030386, Lq: 0.5238900661468506, Le: -1.5308978867530822, loss_Q: 0.007402314264327288\n",
      "Avg. Reward: 0.6811436353469725, sample_ratio: 0.9, weight_bc_loss: 1.0\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 0_best, smoothed reward: 0.6523986187820937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 0_best, smoothed reward: 0.6483800506500028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 0_best, smoothed reward: 0.6342212397501098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 0_best, smoothed reward: 0.6192407262636752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 0_best, smoothed reward: 0.598244279515646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 0_best, smoothed reward: 0.5788081395998873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 0_best, smoothed reward: 0.5581735799653629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 0_best, smoothed reward: 0.5449868415692767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 0_best, smoothed reward: 0.5307652869091581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 0_best, smoothed reward: 0.5174725404948173\n",
      "====================Iteration 20====================\n",
      "Ld: 0.12026184476912022, Lq: 0.5398865842819214, Le: -1.5362488389015199, loss_Q: 0.007531142416410148\n",
      "Avg. Reward: 0.5578584100052316, sample_ratio: 0.8, weight_bc_loss: 1.0\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 0_best, smoothed reward: 0.5073533151058931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 0_best, smoothed reward: 0.4974433113327074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model 0_best, smoothed reward: 0.4921204434482426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation windows:  70%|███████   | 35/50 [00:01<00:00, 26.82it/s]"
     ]
    }
   ],
   "source": [
    "expConfigIdx = 3\n",
    "expParams = getExpConfig(expConfigIdx)\n",
    "visualizeExpConfig(expParams)\n",
    "\n",
    "envConfigIdx = expParams['env_config_idx']\n",
    "envParams = getEnvConfig(envConfigIdx)\n",
    "visualizeEnvConfig(envParams)\n",
    "\n",
    "datasetConfigIdx = expParams['dataset_config_idx']\n",
    "datasetParams = getDatasetConfig(datasetConfigIdx)\n",
    "visualizeDatasetConfig(datasetParams)\n",
    "\n",
    "trafficDataParentPath = f'../../../../data/raw/traffic'\n",
    "env = createEnv(envParams, trafficDataParentPath)\n",
    "env.selectMode(mode=\"train\", type=\"data\")\n",
    "\n",
    "with open(f'../../../../data/processed/offline_dataset/subOptimalAgent_encConfig{datasetConfigIdx}_{envParams[\"sub_agents_idx\"]}.pkl', 'rb') as f:\n",
    "    dataset_expert = pickle.load(f)\n",
    "dataset_off = {\n",
    "    'observations': dataset_expert['uRecord'],     \n",
    "    'actions': dataset_expert['actionsRecord'], \n",
    "    'rewards': dataset_expert['rewardRecord'], \n",
    "    'next_observations': dataset_expert['uNextRecord']\n",
    "}\n",
    "print(f\"Avg. packet loss rate: {np.mean(dataset_expert['rewardRecord'])}\")\n",
    "print(f\"length of dataset: {len(dataset_off['observations'])}\")\n",
    "\n",
    "save_folder = f\"../../../../data/results/dql/config_{expConfigIdx}\"\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "envInterface = EnvInterface(envParams, discrete_state=False)\n",
    "training(\n",
    "    trainingConfig, dataset_off, hyperparams, env, envInterface, save_folder, N_exp_list=[0,1,2]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic_predictor_3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
