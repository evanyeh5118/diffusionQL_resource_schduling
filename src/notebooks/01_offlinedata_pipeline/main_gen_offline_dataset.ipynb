{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '../../../')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from src.difsched.config import getSubAgentConfig, visualizeSubAgentConfig, getDatasetConfig, visualizeDatasetConfig\n",
    "from src.difsched.env import createEnv\n",
    "from src.difsched.agents.mdp import MdpKernel\n",
    "from src.difsched.env import PolicySimulator\n",
    "from src.difsched.agents.Others import RandomPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genDatasetByPolicies(\n",
    "        policies, userMap, num_windows,\n",
    "        env,\n",
    "        N_episodes = 10,\n",
    "        obvMode = \"predicted\",\n",
    "        mode=\"train\",\n",
    "        type=\"data\"\n",
    "    ):\n",
    "    len_episode = int(num_windows/N_episodes)\n",
    "    simResult = {'uRecord': [], 'actionsRecord': [], 'rewardRecord': [], 'uNextRecord': []}\n",
    "    for i in range(N_episodes):\n",
    "        policySimulator = PolicySimulator(env)\n",
    "        policySimulator.loadPolicies(policies, userMap)\n",
    "        policySimulator.setupModes(obvMode=obvMode, mode=mode, type=type)\n",
    "        simResult_ep = policySimulator.runSimulation(num_windows=len_episode, N_episodes=N_episodes)\n",
    "        simResult['actionsRecord'] += simResult_ep['actionsRecord']\n",
    "        simResult['rewardRecord'] += simResult_ep['rewardRecord']\n",
    "        simResult['uNextRecord'] += simResult_ep['uNextRecord']\n",
    "        simResult['uRecord'] += simResult_ep['uRecord']\n",
    "    return simResult\n",
    "\n",
    "def load_mdp_policy(configIdx):\n",
    "    with open(f'../../../data/results/MdpPolicy/mdp_config{configIdx}.pkl', 'rb') as f:\n",
    "        mdpKernelParams = pickle.load(f)\n",
    "    mdpPolicy = MdpKernel()\n",
    "    mdpPolicy.load_policy(mdpKernelParams, policyMode=\"deterministic\", randomR=False)\n",
    "    return mdpPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Dataset Configuration\n",
      "==================================================\n",
      "Number of Users:        8\n",
      "Window Length:          200\n",
      "N_aggregation:          4\n",
      "Dataflow:               thumb_fr\n",
      "Random Seed:            999\n",
      "Resource Bar:           5\n",
      "Bandwidth:              100\n",
      "Sigmoid K List:         [0.3]\n",
      "Sigmoid S List:         [10.0]\n",
      "Sub Agents:             [[0, 0]]\n",
      "User Map:               [[0, 1, 2, 3], [4, 5, 6, 7]]\n",
      "==================================================\n",
      "sub_agent_idxs: [0, 0]\n",
      "==================================================\n",
      "Environment Configuration\n",
      "==================================================\n",
      "Number of Users:        4\n",
      "Window Length:          200\n",
      "Dataflow:               thumb_fr\n",
      "N_aggregation:          4\n",
      "N_r:                    5\n",
      "Resource Bar:           5\n",
      "Bandwidth:              60\n",
      "Sigmoid K List:         [0.3]\n",
      "Sigmoid S List:         [10.0]\n",
      "Random Seed:            999\n",
      "==================================================\n",
      "==================================================\n",
      "Environment Configuration\n",
      "==================================================\n",
      "Number of Users:        4\n",
      "Window Length:          200\n",
      "Dataflow:               thumb_fr\n",
      "N_aggregation:          4\n",
      "N_r:                    5\n",
      "Resource Bar:           5\n",
      "Bandwidth:              60\n",
      "Sigmoid K List:         [0.3]\n",
      "Sigmoid S List:         [10.0]\n",
      "Random Seed:            999\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m     visualizeSubAgentConfig(subAgentParams) \n\u001b[0;32m     23\u001b[0m     policies\u001b[38;5;241m.\u001b[39mappend(load_mdp_policy(sub_agent_idx))\n\u001b[1;32m---> 25\u001b[0m simResult \u001b[38;5;241m=\u001b[39m \u001b[43mgenDatasetByPolicies\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpolicies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musermap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_windows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mN_episodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mN_episodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobvMode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mobvMode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m simResultTotal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muRecord\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m simResult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muRecord\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     30\u001b[0m simResultTotal[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactionsRecord\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m simResult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactionsRecord\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "Cell \u001b[1;32mIn[2], line 15\u001b[0m, in \u001b[0;36mgenDatasetByPolicies\u001b[1;34m(policies, userMap, num_windows, env, N_episodes, obvMode, mode, type)\u001b[0m\n\u001b[0;32m     13\u001b[0m policySimulator\u001b[38;5;241m.\u001b[39mloadPolicies(policies, userMap)\n\u001b[0;32m     14\u001b[0m policySimulator\u001b[38;5;241m.\u001b[39msetupModes(obvMode\u001b[38;5;241m=\u001b[39mobvMode, mode\u001b[38;5;241m=\u001b[39mmode, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtype\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m simResult_ep \u001b[38;5;241m=\u001b[39m \u001b[43mpolicySimulator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunSimulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_windows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlen_episode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_episodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m simResult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactionsRecord\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m simResult_ep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactionsRecord\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     17\u001b[0m simResult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrewardRecord\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m simResult_ep[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrewardRecord\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\Diffusion-offRL\\diffusion_resource_schduling_intra_slice\\src\\notebooks\\01_offlinedata_pipeline\\../../..\\src\\difsched\\env\\PolicySimulator.py:42\u001b[0m, in \u001b[0;36mPolicySimulator.runSimulation\u001b[1;34m(self, num_windows, N_episodes, verbose)\u001b[0m\n\u001b[0;32m     40\u001b[0m u_active \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_observeStates(u, u_predicted)\n\u001b[0;32m     41\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_actions(u_active)\n\u001b[1;32m---> 42\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplyActions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mupdateStates()\n\u001b[0;32m     44\u001b[0m u_next, u_next_predicted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mgetStates()\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\Diffusion-offRL\\diffusion_resource_schduling_intra_slice\\src\\notebooks\\01_offlinedata_pipeline\\../../..\\src\\difsched\\env\\EnvironmentSim.py:48\u001b[0m, in \u001b[0;36mEnvironment.applyActions\u001b[1;34m(self, r)\u001b[0m\n\u001b[0;32m     46\u001b[0m w \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_user)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     47\u001b[0m kappa \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m---> 48\u001b[0m countFailedType1, countActiveType1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msimulatorType1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkappa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfailuresTotal \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m countFailedType1\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactiveTotal \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m countActiveType1\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\Diffusion-offRL\\diffusion_resource_schduling_intra_slice\\src\\notebooks\\01_offlinedata_pipeline\\../../..\\src\\difsched\\env\\Helpers\\Simulators.py:54\u001b[0m, in \u001b[0;36mSimulatorType1.step\u001b[1;34m(self, u, w, r, alpha)\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m active_idx:\n\u001b[1;32m---> 54\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m random\u001b[38;5;241m.\u001b[39mrandom() \u001b[38;5;241m<\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwirelessModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuccessfulPacketCDF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrb\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     55\u001b[0m         successWindow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    if B_type1 > 0 and random.random() < self.wirelessModel.successfulPacketCDF(min(rb[i], B_type1)):\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m        successWindow += 1\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;124;03m        B_type1 -= rb[i]\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Ye\\Documents\\YuYeh_Documents\\L2S\\Projects\\Diffusion-offRL\\diffusion_resource_schduling_intra_slice\\src\\notebooks\\01_offlinedata_pipeline\\../../..\\src\\difsched\\env\\Helpers\\WirelessModel.py:25\u001b[0m, in \u001b[0;36mWirelessModel.successfulPacketCDF\u001b[1;34m(self, r)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msuccessfulPacketCDF\u001b[39m(\u001b[38;5;28mself\u001b[39m, r):\n\u001b[1;32m---> 25\u001b[0m     r_idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearchsorted\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mr_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mN_r\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpacketTransmissionCDF_list[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp_idx][r_idx]\n",
      "File \u001b[1;32mc:\\Users\\Ye\\miniconda3\\envs\\traffic_predictor_3_9\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1400\u001b[0m, in \u001b[0;36msearchsorted\u001b[1;34m(a, v, side, sorter)\u001b[0m\n\u001b[0;32m   1332\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_searchsorted_dispatcher)\n\u001b[0;32m   1333\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearchsorted\u001b[39m(a, v, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, sorter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1334\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1335\u001b[0m \u001b[38;5;124;03m    Find indices where elements should be inserted to maintain order.\u001b[39;00m\n\u001b[0;32m   1336\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1398\u001b[0m \n\u001b[0;32m   1399\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msearchsorted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mside\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msorter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Ye\\miniconda3\\envs\\traffic_predictor_3_9\\lib\\site-packages\\numpy\\core\\fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_windows = 10000\n",
    "N_episodes = 10\n",
    "len_episode = int(num_windows/N_episodes)\n",
    "obvMode = \"predicted\" # \"perfect\" or \"predicted\"\n",
    "savePath = f'../../../data/processed/offline_dataset'\n",
    "\n",
    "for datasetConfigIdx in range(8):\n",
    "    envParams = getDatasetConfig(datasetConfigIdx)\n",
    "    visualizeDatasetConfig(envParams)\n",
    "    trafficDataParentPath =  f'../../../data/raw/traffic'\n",
    "\n",
    "    env = createEnv(envParams, trafficDataParentPath)\n",
    "\n",
    "    usermap = envParams['user_map']\n",
    "    poliocy_set = envParams['sub_agents_idx']\n",
    "    simResultTotal = {'uRecord': [], 'actionsRecord': [], 'rewardRecord': [], 'uNextRecord': []}\n",
    "    for sub_agent_idxs in poliocy_set:\n",
    "        policies = []\n",
    "        print(f\"sub_agent_idxs: {sub_agent_idxs}\")\n",
    "        for sub_agent_idx in sub_agent_idxs:\n",
    "            subAgentParams = getSubAgentConfig(sub_agent_idx)\n",
    "            visualizeSubAgentConfig(subAgentParams) \n",
    "            policies.append(load_mdp_policy(sub_agent_idx))\n",
    "\n",
    "        simResult = genDatasetByPolicies(\n",
    "            policies, usermap, num_windows, \n",
    "            env, \n",
    "            N_episodes = N_episodes, obvMode = obvMode, mode=\"train\", type=\"data\")\n",
    "        simResultTotal['uRecord'] += simResult['uRecord']\n",
    "        simResultTotal['actionsRecord'] += simResult['actionsRecord']\n",
    "        simResultTotal['rewardRecord'] += simResult['rewardRecord']\n",
    "        simResultTotal['uNextRecord'] += simResult['uNextRecord']\n",
    "        \n",
    "    print(f\"Avg. packet loss rate: {np.mean(simResultTotal['rewardRecord'])}\")\n",
    "    print(f\"length of dataset: {len(simResultTotal['uRecord'])}\")\n",
    "    with open(f'{savePath}/subOptimalAgent_encConfig{datasetConfigIdx}_{poliocy_set}.pkl', 'wb') as f:\n",
    "        pickle.dump(simResultTotal, f)\n",
    "    print(f\"saved to {savePath}/subOptimalAgent_encConfig{datasetConfigIdx}_{poliocy_set}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Dataset Configuration\n",
      "==================================================\n",
      "Number of Users:        8\n",
      "Window Length:          200\n",
      "N_aggregation:          4\n",
      "Dataflow:               thumb_fr\n",
      "Random Seed:            999\n",
      "Resource Bar:           5\n",
      "Bandwidth:              100\n",
      "Sigmoid K List:         [0.3]\n",
      "Sigmoid S List:         [10.0]\n",
      "Sub Agents:             [[0, 0]]\n",
      "User Map:               [[0, 1, 2, 3], [4, 5, 6, 7]]\n",
      "==================================================\n",
      "Size of dataset: 10000\n",
      "0.32451573558442404\n"
     ]
    }
   ],
   "source": [
    "envConfigIdx = 0\n",
    "envParams = getDatasetConfig(envConfigIdx)\n",
    "visualizeDatasetConfig(envParams)\n",
    "with open(f'../../../data/processed/offline_dataset/subOptimalAgent_encConfig{envConfigIdx}_{envParams[\"sub_agents_idx\"]}.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)\n",
    "print(f\"Size of dataset: {len(dataset['uRecord'])}\")\n",
    "print(np.mean(dataset['rewardRecord']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffic_predictor_3_9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
